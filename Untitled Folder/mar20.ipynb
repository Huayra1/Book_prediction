{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a33311",
   "metadata": {},
   "source": [
    "We start by importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b5328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4e92a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sc\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf6e17",
   "metadata": {},
   "source": [
    "After importing the packages, we import the dataset.\n",
    "We then clean the dataset by removing, from the copy that is now stored in the ram, the book titles that are not imported correctly or the data is wrongly transformed.\n",
    "We also remove all those titles whos rating count is 0 as they don't have any rating that is the all neccessary response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "97e3d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 3350: expected 12 fields, saw 13\n",
      "Skipping line 4704: expected 12 fields, saw 13\n",
      "Skipping line 5879: expected 12 fields, saw 13\n",
      "Skipping line 8981: expected 12 fields, saw 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_csv(r\"datasets\\books.csv\",sep=\",\", error_bad_lines=False, index_col=\"bookID\")\n",
    "df.columns = df.columns.str.replace(\" \", \"\")\n",
    "df = df[df.ratings_count != 0]\n",
    "df = df[df['num_pages'].apply(lambda x: isinstance(x, (int, float)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e940861",
   "metadata": {},
   "source": [
    "After having cleaned the dataset, we choose only to keep those variables that are not randomly assigned to the book. For example, the isbn number is not kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ca334618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['isbn', 'isbn13'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7f999",
   "metadata": {},
   "source": [
    "We then take on the remaining variables and and transform and/or combine them into new variables that we believe could enhance the model.\n",
    "\n",
    "For example: Publishing date can potentially be quite pointless in itself, but if we make the published date relative to todays date by counting the number of days, we will know how long it is since the book was published.\n",
    "By doing this, we can also find out the rating frequency by taking the number of ratings and dividing it by the number of days since published.\n",
    "\n",
    "Some variables are also duplicated into a logarithmic version. This is done by the reasoning of for example if it turns out that an increase in the age of books generally corresponds with a better rating, then a book that is 1000 years old would be much better rated than any book published the last 50 years, which is a very large portion of the books one find on goodreads.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b511a",
   "metadata": {},
   "source": [
    "The first step in this is to convert 'publication_date' into a dataframe format.\n",
    "We remove all titles that are not comatible with this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "61148319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"publication_date\"] = pd.to_datetime(df[\"publication_date\"], errors='coerce')\n",
    "df = df.dropna();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5a2f6",
   "metadata": {},
   "source": [
    "We then create a categorical variable to find out if the language of the book is english or not. This is because one can assume there are many books written in different languages, but there are also many languages.\n",
    "Creating a model based on each language could cause some very weak data (few datapoints) for some languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "36809cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Categorical variable. 1 if English, 0 if not English\n",
    "df[\"is_eng\"] = df[\"language_code\"].str.contains('eng|en-').astype(int)\n",
    "df.drop(columns=[\"language_code\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67e508",
   "metadata": {},
   "source": [
    "We also try to filter out audiobooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c6b15441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove audiobooks\n",
    "def is_audio(row):\n",
    "    if row['num_pages'] < 30 or \"audio\" in row[\"publisher\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"audio\"] = df.apply(lambda row: is_audio(row), axis=1)\n",
    "df = df[df.audio == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf60627",
   "metadata": {},
   "source": [
    "We then start by creating the transformed variables.\n",
    "We assume that the data was extracted at the end of December 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ded789af",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_date_str = \"2022-12-31\" #yyyy-mm-dd\n",
    "specific_date = pd.to_datetime(specific_date_str)\n",
    "# Find time since the books were published\n",
    "df[\"days_since_published\"] = df[\"publication_date\"].apply(lambda x: (specific_date - x).days)\n",
    "df[\"years_since_published\"] = df.days_since_published / 365.24\n",
    "df[\"log_days_since_published\"] = np.clip(np.log(df.days_since_published), 0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d4ba55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_num_pages\"] = np.log(df.num_pages)\n",
    "df[\"log_r_count\"] = np.log(df.ratings_count)\n",
    "df[\"log_t_count\"] = np.clip(np.log(df.text_reviews_count), 0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aef6d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable that is rating/text_review per day/year/log_day (rating/review density)\n",
    "df[\"r_count_per_day\"] = df.ratings_count / df.days_since_published\n",
    "df[\"t_count_per_day\"] = df.text_reviews_count / df.days_since_published\n",
    "df[\"r_count_per_year\"] = df.ratings_count / df.years_since_published\n",
    "df[\"t_count_per_year\"] = df.text_reviews_count / df.years_since_published\n",
    "df[\"r_count_per_log_day\"] = df.ratings_count / df.log_days_since_published\n",
    "df[\"t_count_per_log_day\"] = df.text_reviews_count / df.log_days_since_published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ee4de078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_r_count_per_day\"] = df.log_r_count / df.days_since_published\n",
    "df[\"log_t_count_per_day\"] = df.log_t_count / df.days_since_published\n",
    "df[\"log_r_count_per_year\"] = df.log_r_count / df.years_since_published\n",
    "df[\"log_t_count_per_year\"] = df.log_t_count / df.years_since_published\n",
    "df[\"log_r_count_per_log_day\"] = df.log_r_count / df.log_days_since_published\n",
    "df[\"log_t_count_per_log_day\"] = df.log_t_count / df.log_days_since_published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "565ce3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ratings_count_per_num_pages\"] = df.ratings_count / df.num_pages\n",
    "df[\"text_reviews_count_per_num_pages\"] = df.text_reviews_count / df.num_pages\n",
    "df[\"ratings_count_per_log_num_pages\"] = df.ratings_count / df.log_num_pages\n",
    "df[\"text_reviews_count_per_log_num_pages\"] = df.text_reviews_count / df.log_num_pages\n",
    "df[\"log_r_count_per_num_pages\"] = df.log_r_count / df.num_pages\n",
    "df[\"log_t_count_per_num_pages\"] = df.log_t_count / df.num_pages\n",
    "df[\"log_r_count_per_log_num_pages\"] = df.log_r_count / df.log_num_pages\n",
    "df[\"log_t_count_per_log_num_pages\"] = df.log_t_count / df.log_num_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c216c0",
   "metadata": {},
   "source": [
    "As we of now have not applied any method for converting the string variables into numerical variables, we drop them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "05ef4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['title', 'authors', 'language_code', 'publication_date', 'publisher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13957f9",
   "metadata": {},
   "source": [
    "As we now expect all the values in the remaining dataframe to be purely numerical, we run a script to filter out all rows with non-numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "87ebdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors='coerce').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "52e1a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:df.shape[1]]\n",
    "y = df['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9e4f79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d761cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1ef35611840>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linmod1 = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "res_linmod1 = linmod1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "aa0146aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (8592,32) and (2148,31) not aligned: 32 (dim 1) != 2148 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [216], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(linmod1\u001b[38;5;241m.\u001b[39mpredict(X_test), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      2\u001b[0m r_sq1 \u001b[38;5;241m=\u001b[39m r2_sore(y_test, y_pred)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR_squared = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr_sq1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\book2\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:397\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (8592,32) and (2148,31) not aligned: 32 (dim 1) != 2148 (dim 0)"
     ]
    }
   ],
   "source": [
    "y_pred = np.clip(res_linmod1.predict(X_test), 0, 5)\n",
    "r_sq1 = r2_sore(y_test, y_pred)\n",
    "print(f\"R_squared = {r_sq1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3c16737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared = 0.09302857750806648\n"
     ]
    }
   ],
   "source": [
    "r_sq1 = res_linmod1.rsquared\n",
    "print(f\"R_squared = {r_sq1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914d133",
   "metadata": {},
   "source": [
    "Before we look closer at ways of simplifying the linear regression model, we have a look at other regression models\n",
    "We start with random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2503b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmod1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfmod1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f8a74846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared = 0.10006584180771294\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.clip(rfmod1.predict(X_test), 0, 5)\n",
    "r_sq1 = r2_score(y_test, y_pred)\n",
    "print(f\"R_squared = {r_sq1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3a0a9811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared = 0.10006584180771294\n"
     ]
    }
   ],
   "source": [
    "r_sq2 = rfmod1.score(X_test, y_test)\n",
    "print(f\"R_squared = {r_sq2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162912a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be2603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68faa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "95b660e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.517299999999998\n",
      "2.9266\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfmod1.predict(X_test)\n",
    "largest_value = y_pred.max()\n",
    "print(largest_value)\n",
    "smallest_value = y_pred.min()\n",
    "print(smallest_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf668b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
